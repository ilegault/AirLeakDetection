{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 9.1: Initial Data Exploration\n",
    "\n",
    "This notebook explores raw sensor data and provides initial insights into:\n",
    "- Data structure and quality\n",
    "- Signal characteristics\n",
    "- Class distributions\n",
    "- FFT frequency content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project to path\n",
    "project_root = Path('..')\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Configure plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = project_root / 'data' / 'processed'\n",
    "RAW_DATA_DIR = project_root / 'data' / 'raw'\n",
    "OUTPUT_DIR = Path('outputs/exploration')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CLASSES = ['No Leak', '1/16\"', '3/32\"', '1/8\"']\n",
    "SAMPLING_RATE = 10000  # Hz\n",
    "N_CHANNELS = 9  # 3 accelerometers × 3 axes\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "try:\n",
    "    X_train = np.load(DATA_DIR / 'X_train.npy')\n",
    "    y_train = np.load(DATA_DIR / 'y_train.npy')\n",
    "    X_val = np.load(DATA_DIR / 'X_val.npy')\n",
    "    y_val = np.load(DATA_DIR / 'y_val.npy')\n",
    "    X_test = np.load(DATA_DIR / 'X_test.npy')\n",
    "    y_test = np.load(DATA_DIR / 'y_test.npy')\n",
    "    \n",
    "    print(\"✓ Processed data loaded successfully\")\n",
    "    print(f\"  Training:   X={X_train.shape}, y={y_train.shape}\")\n",
    "    print(f\"  Validation: X={X_val.shape}, y={y_val.shape}\")\n",
    "    print(f\"  Test:       X={X_test.shape}, y={y_test.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠ Processed data not found. Please run prepare_data.py first.\")\n",
    "    print(\"  Command: python scripts/prepare_data.py --raw-data data/raw --output-dir data/processed\")\n",
    "    X_train = X_val = X_test = None\n",
    "    y_train = y_val = y_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X_train is not None:\n",
    "    # Class distribution\n",
    "    print(\"\\n=== Class Distribution ===\")\n",
    "    for split_name, y in [('Train', y_train), ('Val', y_val), ('Test', y_test)]:\n",
    "        print(f\"\\n{split_name}:\")\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        for class_idx, count in zip(unique, counts):\n",
    "            pct = 100 * count / len(y)\n",
    "            print(f\"  {CLASSES[class_idx]:10s}: {count:4d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Data statistics\n",
    "    print(\"\\n=== Signal Statistics ===\")\n",
    "    X_all = np.vstack([X_train, X_val, X_test])\n",
    "    print(f\"Mean: {X_all.mean():.6f}\")\n",
    "    print(f\"Std:  {X_all.std():.6f}\")\n",
    "    print(f\"Min:  {X_all.min():.6f}\")\n",
    "    print(f\"Max:  {X_all.max():.6f}\")\n",
    "    print(f\"Shape: {X_all.shape} (samples, freq_bins, channels)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Characteristics Per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X_train is not None:\n",
    "    # Compute statistics per class\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    X_all = np.vstack([X_train, X_val, X_test])\n",
    "    y_all = np.hstack([y_train, y_val, y_test])\n",
    "    \n",
    "    for idx, class_name in enumerate(CLASSES):\n",
    "        class_data = X_all[y_all == idx]\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "        \n",
    "        # Plot mean spectrum with std\n",
    "        mean_spec = class_data.mean(axis=(0, 2))\n",
    "        std_spec = class_data.std(axis=(0, 2))\n",
    "        \n",
    "        freq_bins = np.arange(len(mean_spec))\n",
    "        ax.plot(freq_bins, mean_spec, 'b-', linewidth=2, label='Mean')\n",
    "        ax.fill_between(freq_bins, mean_spec - std_spec, mean_spec + std_spec, \n",
    "                         alpha=0.3, label='±1 Std')\n",
    "        \n",
    "        ax.set_title(f'{class_name} (n={len(class_data)})', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Frequency Bin')\n",
    "        ax.set_ylabel('FFT Magnitude')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'signal_characteristics.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"✓ Saved: signal_characteristics.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X_train is not None:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    X_all = np.vstack([X_train, X_val, X_test])\n",
    "    y_all = np.hstack([y_train, y_val, y_test])\n",
    "    \n",
    "    unique, counts = np.unique(y_all, return_counts=True)\n",
    "    colors = sns.color_palette(\"husl\", len(CLASSES))\n",
    "    \n",
    "    bars = ax.bar(CLASSES, counts, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, counts):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "               f'{int(count)}\\n({100*count/len(y_all):.1f}%)',\n",
    "               ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.set_ylabel('Number of Samples', fontsize=12)\n",
    "    ax.set_title('Class Distribution (All Data)', fontsize=14, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"✓ Saved: class_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Channel Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X_train is not None:\n",
    "    # Analyze energy in each channel\n",
    "    X_all = np.vstack([X_train, X_val, X_test])\n",
    "    y_all = np.hstack([y_train, y_val, y_test])\n",
    "    \n",
    "    channel_names = [\n",
    "        'Acc0_X', 'Acc0_Y', 'Acc0_Z',\n",
    "        'Acc1_X', 'Acc1_Y', 'Acc1_Z',\n",
    "        'Acc2_X', 'Acc2_Y', 'Acc2_Z'\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for ch_idx in range(N_CHANNELS):\n",
    "        channel_data = X_all[:, :, ch_idx]\n",
    "        channel_energy = np.sum(channel_data ** 2, axis=1)\n",
    "        \n",
    "        ax = axes[ch_idx]\n",
    "        for class_idx, class_name in enumerate(CLASSES):\n",
    "            mask = y_all == class_idx\n",
    "            ax.hist(channel_energy[mask], bins=20, alpha=0.6, label=class_name)\n",
    "        \n",
    "        ax.set_title(f'{channel_names[ch_idx]}', fontweight='bold')\n",
    "        ax.set_xlabel('Signal Energy')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'channel_energy_distribution.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"✓ Saved: channel_energy_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X_train is not None:\n",
    "    X_all = np.vstack([X_train, X_val, X_test])\n",
    "    \n",
    "    print(\"\\n=== Data Quality Checks ===\")\n",
    "    \n",
    "    # Check for NaN/Inf\n",
    "    nan_count = np.isnan(X_all).sum()\n",
    "    inf_count = np.isinf(X_all).sum()\n",
    "    print(f\"\\nNaN values:     {nan_count} ({100*nan_count/X_all.size:.4f}%)\")\n",
    "    print(f\"Inf values:     {inf_count} ({100*inf_count/X_all.size:.4f}%)\")\n",
    "    \n",
    "    # Check for zeros\n",
    "    zero_count = (X_all == 0).sum()\n",
    "    print(f\"Zero values:    {zero_count} ({100*zero_count/X_all.size:.4f}%)\")\n",
    "    \n",
    "    # Check value ranges\n",
    "    print(f\"\\nValue range:    [{X_all.min():.6f}, {X_all.max():.6f}]\")\n",
    "    print(f\"Mean:           {X_all.mean():.6f}\")\n",
    "    print(f\"Std:            {X_all.std():.6f}\")\n",
    "    \n",
    "    # Check shape consistency\n",
    "    print(f\"\\nShape consistency: OK (all samples have shape {X_all.shape[1:]})\")\n",
    "    \n",
    "    print(\"\\n✓ Data quality assessment complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X_train is not None:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DATA EXPLORATION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nDataset size:    {len(X_train) + len(X_val) + len(X_test)} samples\")\n",
    "    print(f\"Train/Val/Test:  {len(X_train)}/{len(X_val)}/{len(X_test)}\")\n",
    "    print(f\"Classes:         {len(CLASSES)} ({', '.join(CLASSES)})\")\n",
    "    print(f\"Features:        {X_train.shape[1]} frequency bins × {X_train.shape[2]} channels\")\n",
    "    print(f\"\\nOutputs saved to: {OUTPUT_DIR}\")\n",
    "    print(\"  - signal_characteristics.png\")\n",
    "    print(\"  - class_distribution.png\")\n",
    "    print(\"  - channel_energy_distribution.png\")\n",
    "    print(\"\\n✓ Data exploration complete!\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"  1. Review signal characteristics per class\")\n",
    "    print(\"  2. Check for data quality issues\")\n",
    "    print(\"  3. Verify class balance\")\n",
    "    print(\"  4. Go to 02_fft_comparison.ipynb to validate FFT method\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}